{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from Word2VecTransformer import Embedding_Word2Vec\n",
    "from FastTextTransformer import FastTextTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from threading import Thread\n",
    "from ClearTransformData import Cleardataset\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from train_model import BestModelFinder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_VAR=\"/home/hsiebenounganka/Bureau/text_mining/\"\n",
    "ft_home =HOME_VAR+'textmining_with_structured_directory/data/fastText-0.2.0/fasttext'\n",
    "Input=HOME_VAR+\"textmining_with_structured_directory/src/models/FastTestFolder/xtrain.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = [(\"fastText\", FastTextTransformer(inputFile=Input,ft_home=ft_home,size=300)) , (\"SVM\", SVC())]\n",
    "param12={\"SVM__kernel\":['rbf', 'linear', 'poly'], 'SVM__C':[1, 10, 100]}\n",
    "model13 = [(\"fastText\",FastTextTransformer(inputFile=Input,ft_home=ft_home,size=300)) , (\"GradientBoosting\",GradientBoostingClassifier())]\n",
    "param13={\"GradientBoosting__n_estimators\": [20, 30, 40, 50, 60, 70, 80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfinal=[(model12,param12),(model13,param13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut du programme\n",
      "Clear data\n",
      "data cleared in:1.516355276107788\n",
      "Execute and save modele:\n",
      "Model lauch:[('fastText', <FastTextTransformer.FastTextTransformer object at 0x7f7c53ef21d0>), ('SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))]_{'SVM__kernel': ['rbf', 'linear', 'poly'], 'SVM__C': [1, 10, 100]}Model lauch:[('fastText', <FastTextTransformer.FastTextTransformer object at 0x7f7c53ef2278>), ('GradientBoosting', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False))]_{'GradientBoosting__n_estimators': [20, 30, 40, 50, 60, 70, 80]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hsiebenounganka/Bureau/text_mining/textmining_with_structured_directory/src/models/train_model.py\", line 91, in run\n",
      "    self.__ApplyModel(self.X,self.Y,model=mod,param=par)\n",
      "  File \"/home/hsiebenounganka/Bureau/text_mining/textmining_with_structured_directory/src/models/train_model.py\", line 81, in __ApplyModel\n",
      "    modele.fit(X,Y)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\", line 722, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\", line 1191, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\", line 711, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 920, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 528, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\", line 265, in fit\n",
      "    Xt, fit_params = self._fit(X, y, **fit_params)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\", line 230, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\", line 342, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\", line 616, in _fit_transform_one\n",
      "    res = transformer.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/home/hsiebenounganka/Bureau/text_mining/textmining_with_structured_directory/src/models/FastTextTransformer.py\", line 47, in fit\n",
      "    self.model_wrapper = FT_wrapper.train(self.ft_home, self.inputFile,model=self.model,size=self.size,word_ngrams=self.word_ngrams)\n",
      "  File \"/home/hsiebenounganka/.local/lib/python3.6/site-packages/gensim/models/deprecated/fasttext_wrapper.py\", line 246, in train\n",
      "    model = cls.load_fasttext_format(output_file)\n",
      "  File \"/home/hsiebenounganka/.local/lib/python3.6/site-packages/gensim/models/deprecated/fasttext_wrapper.py\", line 274, in load_fasttext_format\n",
      "    model.load_binary_data(encoding=encoding)\n",
      "  File \"/home/hsiebenounganka/.local/lib/python3.6/site-packages/gensim/models/deprecated/fasttext_wrapper.py\", line 300, in load_binary_data\n",
      "    self.load_model_params(f)\n",
      "  File \"/home/hsiebenounganka/.local/lib/python3.6/site-packages/gensim/models/deprecated/fasttext_wrapper.py\", line 305, in load_model_params\n",
      "    magic, version = self.struct_unpack(file_handle, '@2i')\n",
      "  File \"/home/hsiebenounganka/.local/lib/python3.6/site-packages/gensim/models/deprecated/fasttext_wrapper.py\", line 393, in struct_unpack\n",
      "    return struct.unpack(fmt, file_handle.read(num_bytes))\n",
      "struct.error: unpack requires a buffer of 8 bytes\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model lauched successfull. Execution times:68097.41196084023\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "if __name__==\"__main__\":\n",
    "    print(\"Debut du programme\")\n",
    "    \n",
    "    #testData=pd.read_csv(\"../../data/TestData.csv\")\n",
    "    print(\"Clear data\")\n",
    "    t1=time.time()\n",
    "    \n",
    "    if not os.path.exists(\"../../data/TrainDataClean.csv\"):\n",
    "        trainData=pd.read_csv(\"../../data/TrainData.csv\")\n",
    "        XtrainClean=Cleardataset().fit(trainData.description).transform(trainData.description)\n",
    "        trainData.description=XtrainClean\n",
    "        trainData.to_csv(\"../../data/TrainDataClean.csv\",index=False)\n",
    "    else:\n",
    "        XtrainClean=pd.read_csv(\"../../data/TrainDataClean.csv\")\n",
    "\n",
    "    print(\"data cleared in:{}\".format(time.time()-t1))\n",
    "   \n",
    "    path_to_modele=HOME_VAR+\"textmining_with_structured_directory/src/data/\"\n",
    "    \n",
    "    modelList1 = [modelfinal[0]]\n",
    "    modelList2 = [modelfinal[1]]\n",
    "\n",
    "       \n",
    "    Thread1 = BestModelFinder(X=XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList1,path=path_to_modele)\n",
    "    Thread2 = BestModelFinder(XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList2,path=path_to_modele)\n",
    "\n",
    "    print(\"Execute and save modele:\")\n",
    "    Thread1.start()\n",
    "    Thread2.start()\n",
    "\n",
    "    Thread1.join()\n",
    "    Thread2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
