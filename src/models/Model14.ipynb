{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from Word2VecTransformer import Embedding_Word2Vec\n",
    "from FastTextTransformer import FastTextTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from threading import Thread\n",
    "from ClearTransformData import Cleardataset\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from train_model import BestModelFinder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_VAR=\"/home/arakotoarijaona/Bureau/arakotoarijaona/\"\n",
    "ft_home =HOME_VAR+'textmining_with_structured_directory/data/fastText-0.2.0/fasttext'\n",
    "Input=HOME_VAR+\"textmining_with_structured_directory/src/models/FastTestFolder/xtrain.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = [(\"tfidf\",TfidfVectorizer()) , (\"SVM\", SVC())]\n",
    "param12={\"SVM__kernel\":['rbf', 'linear', 'poly'], 'SVM__C':[1, 10, 100]}\n",
    "# model13 = [(\"tfidf\",TfidfVectorizer()) , (\"GradientBoosting\",GradientBoostingClassifier())]\n",
    "# param13={\"GradientBoosting__n_estimators\": [20, 30, 40, 50, 60, 70, 80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfinal=[(model12,param12)]# ,(model13,param13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut du programme\n",
      "Clear data\n",
      "data cleared in:7.850535154342651\n",
      "Execute and save modele:\n",
      "Model lauch:[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))]_{'SVM__kernel': ['rbf', 'linear', 'poly'], 'SVM__C': [1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "if __name__==\"__main__\":\n",
    "    print(\"Debut du programme\")\n",
    "    \n",
    "    #testData=pd.read_csv(\"../../data/TestData.csv\")\n",
    "    print(\"Clear data\")\n",
    "    t1=time.time()\n",
    "    \n",
    "    if not os.path.exists(\"../../data/TrainDataClean.csv\"):\n",
    "        trainData=pd.read_csv(\"../../data/TrainData.csv\")\n",
    "        XtrainClean=Cleardataset().fit(trainData.description).transform(trainData.description)\n",
    "        trainData.description=XtrainClean\n",
    "        trainData.to_csv(\"../../data/TrainDataClean.csv\",index=False)\n",
    "    else:\n",
    "        XtrainClean=pd.read_csv(\"../../data/TrainDataClean.csv\")\n",
    "\n",
    "    print(\"data cleared in:{}\".format(time.time()-t1))\n",
    "   \n",
    "    path_to_modele=HOME_VAR+\"textmining_with_structured_directory/src/data/\"\n",
    "    \n",
    "    modelList1 = modelfinal\n",
    "    #modelList2 = [modelfinal[1]]\n",
    "\n",
    "       \n",
    "    Thread1 = BestModelFinder(X=XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList1,path=path_to_modele)\n",
    "    #Thread2 = BestModelFinder(XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList2,path=path_to_modele)\n",
    "\n",
    "    print(\"Execute and save modele:\")\n",
    "    Thread1.start()\n",
    "    #Thread2.start()\n",
    "\n",
    "    Thread1.join()\n",
    "    #Thread2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
