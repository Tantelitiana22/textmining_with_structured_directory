{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from Word2VecTransformer import Embedding_Word2Vec\n",
    "from FastTextTransformer import FastTextTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from threading import Thread\n",
    "from ClearTransformData import Cleardataset\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from train_model import BestModelFinder\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_VAR=\"/home/hsiebenounganka/Bureau/text_mining/\"\n",
    "ft_home =HOME_VAR+'textmining_with_structured_directory/data/fastText-0.2.0/fasttext'\n",
    "Input=HOME_VAR+\"textmining_with_structured_directory/src/models/FastTestFolder/xtrain.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = [(\"w2v\", Embedding_Word2Vec(n_size = 300,n_window = 5,n_min_count = 10,n_workers = 4)), (\"SVM\", SVC())]\n",
    "param12={\"SVM__kernel\":['rbf', 'linear', 'poly'], 'SVM__C':[1, 10, 100]}\n",
    "model13 = [(\"w2v\", Embedding_Word2Vec(n_size = 300,n_window = 5,n_min_count = 10,n_workers = 4)), (\"GradientBoosting\",GradientBoostingClassifier())]\n",
    "param13={\"GradientBoosting__n_estimators\": [20, 30, 40, 50, 60, 70, 80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfinal=[(model12,param12),(model13,param13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut du programme\n",
      "Clear data\n",
      "data cleared in:20.318445444107056\n",
      "Execute and save modele:\n",
      "Model lauch:[('w2v', <Word2VecTransformer.Embedding_Word2Vec object at 0x7fa94052c630>), ('SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))]_{'SVM__kernel': ['rbf', 'linear', 'poly'], 'SVM__C': [1, 10, 100]}\n",
      "Model lauch:[('w2v', <Word2VecTransformer.Embedding_Word2Vec object at 0x7fa94052c6a0>), ('GradientBoosting', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False))]_{'GradientBoosting__n_estimators': [20, 30, 40, 50, 60, 70, 80]}\n",
      "Model lauched successfull. Execution times:72067.6344769001\n",
      "Model lauched successfull. Execution times:80485.1064081192\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "if __name__==\"__main__\":\n",
    "    print(\"Debut du programme\")\n",
    "    \n",
    "    #testData=pd.read_csv(\"../../data/TestData.csv\")\n",
    "    print(\"Clear data\")\n",
    "    t1=time.time()\n",
    "    \n",
    "    if not os.path.exists(\"../../data/TrainDataClean.csv\"):\n",
    "        trainData=pd.read_csv(\"../../data/TrainData.csv\")\n",
    "        XtrainClean=Cleardataset().fit(trainData.description).transform(trainData.description)\n",
    "        trainData.description=XtrainClean\n",
    "        trainData.to_csv(\"../../data/TrainDataClean.csv\",index=False)\n",
    "    else:\n",
    "        XtrainClean=pd.read_csv(\"../../data/TrainDataClean.csv\")\n",
    "\n",
    "    print(\"data cleared in:{}\".format(time.time()-t1))\n",
    "   \n",
    "    path_to_modele=\"../data/\"\n",
    "    \n",
    "    modelList1 = [modelfinal[0]]\n",
    "    modelList2 = [modelfinal[1]]\n",
    "\n",
    "       \n",
    "    Thread1 = BestModelFinder(X=XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList1,path=path_to_modele)\n",
    "    Thread2 = BestModelFinder(XtrainClean.description,Y=XtrainClean.Labels,ListParamModel=modelList2,path=path_to_modele)\n",
    "\n",
    "    print(\"Execute and save modele:\")\n",
    "    Thread1.start()\n",
    "    Thread2.start()\n",
    "\n",
    "    Thread1.join()\n",
    "    Thread2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
